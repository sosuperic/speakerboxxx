# Create wavs from the parameters generated by test.lua

using WAV
using WORLD
using HDF5

# using PyCall
# matplotlib = pyimport("matplotlib")
# PyDict(matplotlib["rcParams"])["figure.figsize"] = (12, 5)
# using PyPlot

# using Images

# SPECTRAL_PARAMS_PATH = "outputs/spectral/acoustic_only"
SPECTRAL_PARAMS_PATH = "outputs/spectral/full_pipeline_f0interpolate_normalized"
# SPECTRAL_PARAMS_PATH = "outputs_two_datasets/spectral/full_pipeline"
OUTPUTS_WAV_PATH = "outputs/wav"
# OUTPUTS_WAV_PATH = "outputs_two_datasets/wav"

NORMALIZED = true
SILENCE_IF_NOTVOICED = false

mean = h5read(joinpath("data/processed/cmu_us_slt_arctic/acoustic_targets_f0interpolate_normalized/", "mean.h5"), "data")               # (time, features (84))
stddev = h5read(joinpath("data/processed/cmu_us_slt_arctic/acoustic_targets_f0interpolate_normalized/", "stddev.h5"), "data")

function generate_and_save_wav(rec_fn, i)
    # rec_fn = "arctic_a0120.h5"
    println(i)
    if i == 1 || i == 74
        return
    end
    rec = splitext(rec_fn)[1]
    println(rec)
    fp = joinpath(SPECTRAL_PARAMS_PATH, rec_fn)
    data = h5read(fp, "data")               
    data = transpose(data)                  # (time, features (84))

    # Restore mean stddev
    if NORMALIZED
        for i=2:size(data)[2]                  # features
            data[1:end, i] *= stddev[i-1]
            data[1:end, i] += mean[i-1]
        end
    end

    voiced = data[1:end,1]
    log_f0  = data[1:end,2]
    f0 = 10.^(log_f0 - 1e-10)               # (381,)        NOTE the eps
    
    # Silence if voiced flag is 1
    if SILENCE_IF_NOTVOICED
        for i=1:size(voiced)[1]
            if voiced[i] < 0.25
                f0[i] = 0.0
            end
        end
    end

    sp_mc = data[1:end, 3:3+(41-1)]         # (381, 41)
    ap_mc = data[1:end, 3+41:end]           # (381, 41)

    sp_mc = transpose(sp_mc)
    ap_mc = transpose(ap_mc)

    α = 0.41
    fs = 16000
    period = 5.0
    fftlen = get_fftsize_for_cheaptrick(fs)
    wav_len = round(Int, size(f0)[1] * fs * period / 1000)
    approx_sp = mc2sp(sp_mc, α, fftlen)
    approx_ap = mc2sp(ap_mc, α, fftlen)

    # Read targets to compare
    # targets = h5read(joinpath("data/processed/cmu_us_slt_arctic/acoustic_targets/", "$rec.h5"), "y")
    # targets_f0 = targets[2,1:end]
    # targets_sp_mc = targets[3:3+(41-1), 1:end]
    # targets_ap_mc = targets[3+(41-1):end, 1:end]
    # writedlm("log_f0.txt", log_f0)
    # writedlm("targets_f0.txt", squeeze(targets_f0, 1))
    # imshow(10log10(targets_sp_mc + 1e-6), origin="lower", aspect="auto")
    # colorbar()
    # quit()

    # timeaxis = Array(linspace(0, length(f0) * 0.005, length(f0)))
    # save(f0, "test_f0.png")
    # # imwrite(timeaxis, f0)
    # quit()

    # tmp = wav_len / 16000 / (5 / 1000)
    # # println(tmp)
    # println(size(f0))
    # println(wav_len)
    # println(size(sp_mc))
    # # println(size(ap_mc))
    # println(size(approx_sp))
    # # println(size(approx_ap))
    # println(f0)
    # println(sp_mc)
    # quit()


    y = synthesis(f0, approx_sp, approx_ap, period, fs, wav_len)

    wavwrite(y, joinpath(OUTPUTS_WAV_PATH, "$rec.wav"), Fs=fs)
end

recs = readdir(SPECTRAL_PARAMS_PATH)
i = 1
for rec_fn in recs
    if rec_fn == ".DS_Store"
        continue
    end
    generate_and_save_wav(rec_fn, i)
    i += 1
end
